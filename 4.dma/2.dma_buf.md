
# Buffer Sharing and Synchronization (dma-buf)

reference:  
[Buffer Sharing and Synchronization (dma-buf)](https://docs.kernel.org/driver-api/dma-buf.html)  
[dma-buf 由浅入深](https://blog.csdn.net/hexiaolong2009/article/details/102596744)

dma-buf 子系统提供了用于跨多个设备驱动程序和子系统共享硬件 (DMA) 访问缓冲区以及同步异步硬件
访问的框架。不管是 Video、Camera 还是 Display、GPU，它们的buffer都来自于ION，而 ION 正是
基于 dma-buf 实现的。


最简单的 dma-buf 驱动程序
历史
dma-buf 最初的原型为 shrbuf，由 Marek Szyprowski （Samsung）于2011年8月2日首次提出，他实现了 “Buffer Sharing” 的概念验证（Proof-of-Concept），并在三星平台的 V4L2 驱动中实现了 camera 与 display 的 buffer 共享问题。



================================================================================

它的三个主要组件是：
1. dma-buf，表示 sg_table 并作为文件描述符暴露给用户空间，以允许在设备之间传递
2. fence，它提供一种机制，在一个设备完成访问时发出信号
3. 预留，管理与缓冲区(buffer)关联的共享或独占fence(s)。

## Shared DMA Buffers

任何希望使用 DMA 缓冲区的设备驱动程序都可以作为缓冲区的“导出者(exporter)”、缓冲区的“用户(user)”或“导入者(importer)”。

假设驱动程序 A 想使用驱动程序 B 创建的缓冲区，那么我们将 B 称为导出者，将 A 称为缓冲区用户/导入者。

导出者（The exporter）
* 使用 struct dma_buf_ops 实现和管理缓冲区
* 允许其他用户通过使用 dma_buf 共享 API 来共享缓冲区，
* 管理缓冲区分配的详细信息，包装在 struct dma_buf
* 决定分配的实际后备存储
* 并负责该缓冲区的所有（共享）用户的散列表迁移。

导入者（The buffer-user）
* 是缓冲区的（许多）共享用户之一。
* 不需要担心缓冲区是如何分配的，或者在哪里分配的。
* 并且需要一种机制来访问构成内存中缓冲区的分散列表，映射到自己的地址空间，以便它可以访问同一内存区域。该接口由 struct dma_buf_attachment 提供。

dma-buf 缓冲区共享框架的任何导出者或用户都必须在各自的 Kconfig 中具有“select DMA_SHARED_BUFFER”。

## Userspace Interface Notes

大多数情况下，DMA 缓冲区文件描述符只是用户空间的不透明对象，因此公开的通用接口非常少。但有一些事情需要明确：

* 从内核 3.12 开始，dma-buf FD 支持 llseek 系统调用，但仅限 offset=0 且 wherece=SEEK_END|SEEK_SET。支持 SEEK_SET 以允许通常的大小发现模式 size = SEEK_END(0); SEEK_SET(0)。所有其他 llseek 操作都会报告 -EINVAL。
如果 dma-buf FD 上的 llseek 不支持，内核将针对所有情况报告 -ESPIPE。用户空间可以使用它来检测对使用 llseek 发现 dma-buf 大小的支持。

* 为了避免 exec 上的 fd 泄漏，必须在文件描述符上设置 FD_CLOEXEC 标志。这不仅仅是资源泄漏，而且是潜在的安全漏洞。它可以通过泄漏的 fd 为新执行的应用程序提供对缓冲区的访问权限，否则不应允许其访问该缓冲区。
通过单独的 fcntl() 调用来执行此操作，而不是在创建 fd 时以原子方式执行此操作，问题在于，这在多线程应用程序中本质上是很活跃的[3]。当库代码打开/创建文件描述符时，问题会变得更糟，因为应用程序甚至可能不知道文件描述符。
为了避免这个问题，用户空间必须有一种方法来请求在创建 dma-buf fd 时设置 O_CLOEXEC 标志。因此，导出驱动程序提供的用于创建 dmabuf fd 的任何 API 都必须提供一种方法，让用户空间控制传递给 的 O_CLOEXEC 标志的设置dma_buf_fd()。

* 还支持 DMA 缓冲区内容的内存映射。有关完整详细信息，请参阅下面有关CPU 访问 DMA 缓冲区对象的讨论。

* DMA 缓冲区 FD 也是可轮询的，有关详细信息，请参阅下面的隐式栅栏轮询支持。

* DMA 缓冲区 FD 还支持一些 dma-buf 特定的 ioctl，有关详细信息，请参阅 下面的DMA 缓冲区 ioctl。

## Basic Operation and Device DMA Access

对于设备 DMA 访问共享 DMA 缓冲区，通常的操作顺序相当简单：

1. 导出器使用 DEFINE_DMA_BUF_EXPORT_INFO()并调用dma_buf_export()将私有缓冲区对象包装到dma_buf. 然后它通过调用dma_buf_fd()将其dma_buf作为文件描述符导出到用户空间。

2. 用户空间将此文件描述符传递给希望共享此缓冲区的所有驱动程序：首先，使用dma_buf_get()将文件描述符转换为dma_buf。 然后使用dma_buf_attach()将缓冲区附加到设备。

到目前为止，导出者仍然可以自由迁移或重新分配后备存储。

3. 一旦缓冲区连接到所有设备，用户空间就可以启动对共享缓冲区的 DMA 访问。在内核中，这是通过调用 dma_buf_map_attachment()和 dma_buf_unmap_attachment() 来完成的。

4. 一旦驱动程序使用完共享缓冲区，它就需要调用 dma_buf_detach()（清理所有映射后），然后调用dma_buf_put() 释放通过dma_buf_get()获取的引用。

对于详细的语义导出器预计实现请参阅 dma_buf_ops。

## CPU Access to DMA Buffer Objects

支持 CPU 访问 DMA 缓冲区对象有多种原因：

* 内核中的回退操作，例如，当设备通过 USB 连接时，内核需要先对数据进行混洗，然后再将其发送出去。缓存一致性是通过将任何事务与调用dma_buf_begin_cpu_access()和dma_buf_end_cpu_access() 访问括起来来处理的。

由于大多数内核内部 dma-buf 访问需要整个缓冲区，因此引入了 vmap 接口。请注意，在非常旧的 32 位体系结构上，vmalloc 空间可能有限，并导致 vmap 调用失败。

接口：
```c
void \*dma_buf_vmap(struct dma_buf \*dmabuf, struct iosys_map \*map)
void dma_buf_vunmap(struct dma_buf \*dmabuf, struct iosys_map \*map)
```
如果导出器中没有 vmap 支持，或者 vmalloc 空间不足，则 vmap 调用可能会失败。请注意，dma-buf 层会保留所有 vmap 访问的引用计数，并且仅当不存在 vmapping 时才会向下调用导出器的 vmap 函数，并且仅取消映射一次。通过获取互斥锁dma_buf.lock来防止并发 vmap/vunmap 调用。

* 为了在导入端与现有的用户空间接口完全兼容，现有的用户空间接口可能已经支持 mmap'ing 缓冲区。这在许多处理管道中都是需要的（例如，将软件渲染的图像馈送到硬件管道、缩略图创建、快照……）。此外，Android 的 ION 框架已经支持这一点，并且需要 DMA 缓冲区文件描述符来替换 ION 缓冲区 mmap 支持。

没有特殊的接口，用户空间只是在 dma-buf fd 上调用 mmap。但与 CPU 访问一样，需要将实际访问括起来，这是由 ioctl (DMA_BUF_IOCTL_SYNC) 处理的。请注意，DMA_BUF_IOCTL_SYNC 可能会因 -EAGAIN 或 -EINTR 而失败，在这种情况下必须重新启动。

某些系统可能需要某种缓存一致性管理，例如当通过 dma-buf 同时访问 CPU 和 GPU 域时。为了避免这个问题，有开始/结束一致性标记，直接转发到现有的 dma-buf 设备驱动程序 vfunc hooks。用户空间可以通过 DMA_BUF_IOCTL_SYNC ioctl 使用这些标记。该序列的使用方式如下：
1. mmap dma-buf fd
2. 对于 CPU 中的每个绘图/上传周期 1. SYNC_START ioctl，2. 读/写 mmap 区域 3. SYNC_END ioctl。您可以根据需要多次重复此操作（例如 GPU 或扫描输出设备消耗新数据）
3. 一旦您不再需要缓冲区，就可以使用 munmap

为了正确性和最佳性能，在访问映射地址时，始终需要分别在之前和之后使用 SYNC_START 和 SYNC_END。用户空间不能依赖一致的访问，即使在某些系统中它只是在不调用这些 ioctl 的情况下工作。

* 作为用户空间处理管道中的 CPU 后备。

与内核 cpu 访问的动机类似，给定导入子系统的用户空间代码可以使用与本机缓冲区对象相同的接口来导入 dma-buf 缓冲区对象，这一点也很重要。这对于 drm 来说尤其重要，因为当代 OpenGL、X 和其他驱动程序的用户空间部分非常庞大，并且需要重新设计它们以使用不同的方式来映射缓冲区，这相当具有侵入性。

当前 dma-buf 接口中的假设是重定向初始 mmap 就足够了。对一些现有子系统的调查表明，似乎没有驱动程序会做任何邪恶的事情，例如与设备上未完成的异步处理同步或在故障时分配特殊资源。所以希望这足够好，因为添加接口来拦截页面错误并允许 pte 击落会大大增加复杂性。

界面：
```c
int dma_buf_mmap(struct dma_buf \*, struct vm_area_struct \*,
               unsigned long);
```
如果导入子系统只是提供一个特殊用途的 mmap 调用来在用户空间中设置映射，则调用 do_mmapdma_buf.file将同样实现 dma-buf 对象的目的。







# old doc

从上面的代码来看，要实现一个 dma-buf exporter驱动，需要执行3个步骤：
1. dma_buf_ops
2. DEFINE_DMA_BUF_EXPORT_INFO
3. dma_buf_export()

**注意：** 其中 *dma_buf_ops* 的回调接口中，如下接口又是必须要实现的，缺少任何一个都将导致 *dma_buf_export()* 函数调用失败！

- map_dma_buf
- unmap_dma_buf
- map
- map_atomic
- mmap
- release



| 内核态调用               | 对应 dma_buf_ops 中的接口 | 说明                                                         |
| ------------------------ | ------------------------- | ------------------------------------------------------------ |
| dma_buf_kmap()           | map                       |                                                              |
| dma_buf_kmap_atomic()    | map_atomic                |                                                              |
| dma_buf_vmap()           | vmap                      |                                                              |
| dma_buf_attach()         | attach                    | 该函数实际是 *“dma-buf attach device”* 的缩写，用于建立一个 dma-buf 与 device 的连接关系，这个连接关系被存放在新创建的 *dma_buf_attachment* 对象中，供后续调用 *dma_buf_map_attachment()* 使用。如果 device 对后续的 map attachment 操作没有什么特殊要求，可以不实现。 |
| dma_buf_map_attachment() | map_dma_buf               | 该函数实际是 *“dma-buf map attachment into sg_table”* 的缩写，它主要完成2件事情：1. 生成 sg_table     2. 同步 Cache |
|                          |                           |                                                              |
|                          |                           |                                                              |


# DMA

## kmap / vmap
from https://blog.csdn.net/hexiaolong2009/article/details/102596761

**CPU Access**

Starting from linux-3.4, dma-buf introduces a CPU operation interface,
allowing developers to directly use the CPU in the kernel space to access 
the physical memory of dma-buf.

The following dma-buf API implements CPU access to dma-buf memory in kernel space:
- dma_buf_kmap()
- dma_buf_kmap_atomic()
- dma_buf_vmap()


Through the dma_buf_kmap() / dma_buf_vmap() operation, the actual physical 
memory can be mapped to the kernel space, and converted into a virtual address 
that the CPU can continuously access, so that subsequent software can directly 
read and write this physical memory. Therefore, regardless of whether the buffer 
is physically continuous, the virtual addresses after kmap/vmap mapping must be 
continuous.

The above three interfaces correspond to the kmap(), kmap_atomic() and vmap() 
functions in the linux memory management subsystem (MM) respectively. 
The differences between the three are as follows:

| function | description |
|----|----|
| kmap()        | can only map 1 page at a time, may sleep, and can only be called in the process context |
| kmap_atomic() | can only map 1 page at a time, will not sleep, and can be called in interrupt context |
| vmap()        | can map multiple pages at a time, and these pages can be physically discontinuous, and can only be called in the process context |


## map attachment
from https://blog.csdn.net/hexiaolong2009/article/details/102596772

**DMA Access**

There are two main APIs provided by dma-buf for DMA hardware access:
- dma_buf_attach()
- dma_buf_map_attachment()
These two interfaces are called in a strict order, they must be attached first,
and then map attachment, because the parameters of the latter are provided by 
the former, so these two interfaces are usually inseparable.

The reverse operation interfaces corresponding to the above two APIs are: dma_buf_dettach() and dma_buf_unmap_attachment()


**sg_table**

sg_table is the ultimate goal of dma-buf for DMA hardware access,
and it is also the only way for DMA hardware to access discrete memory!

sg_table is essentially a linked list composed of many single physically 
continuous buffers, but this linked list is discrete as a whole, so it can 
well describe the discrete buffers allocated from high-end memory. 
Of course, it can also be used to describe physically continuous buffers 
allocated from low-end memory.

sg_table represents the entire linked list, and each of its linked list items 
is represented by scatterlist. Therefore, a scatterlist corresponds to a 
physically continuous buffer. We can obtain the physical address and length 
of the buffer corresponding to a scatterlist through the following interface:
- sg_dma_address(sgl)
- sg_dma_len(sgl)

With the physical address and length of the buffer, we can configure these 
two parameters into the DMA hardware register, so that the DMA hardware can 
access the buffer. So how to access the entire discrete buffer? Of course, 
use a for loop to continuously parse the scatterlist and configure the DMA 
hardware registers continuously!


**dma_buf_attach()**

This function is actually the abbreviation of "dma-buf attach device", 
which is used to establish a connection relationship between dma-buf and device.
This connection relationship is stored in the newly created dma_buf_attachment 
object for subsequent calls to dma_buf_map_attachment().

This function corresponds to the attach callback interface in dma_buf_ops. 
If the device has no special requirements for subsequent map attachment 
operations, it may not be implemented.

**dma_buf_map_attachment()**

This function is actually the abbreviation of "dma-buf map attachment into sg_table", 
it mainly completes 2 things:
1. Generate sg_table: 
The choice to return sg_table instead of physical address 
is for compatibility with all DMA hardware (with or without IOMMU), since sg_table 
can represent both contiguous and non-contiguous physical memory.

2. Synchronize Cache:
The purpose of synchronizing the Cache is to prevent the buffer from being filled 
by the CPU in advance, and the data is temporarily stored in the Cache instead of 
the DDR, causing the DMA to access not the latest valid data. Such problems can 
be avoided by writing back the data in the Cache to the DDR. Similarly, after 
the DMA accesses the memory, the Cache needs to be set to be invalid, so that 
the subsequent CPU can directly read the memory data from the DDR (not from the Cache). 
Usually we use the following streaming DMA mapping interface to complete Cache 
synchronization:
- dma_map_single() / dma_unmap_single()
- dma_map_page() / dma_unmap_page()
- dma_map_sg() / dma_unmap_sg()

For more descriptions of the dma_map_*() functions, recommen to read 
https://blog.csdn.net/jasonchen_gbd/article/details/79462064

dma_buf_map_attachment() corresponds to the map_dma_buf callback interface in 
dma_buf_ops, the callback interface (including unmap_dma_buf) is mandatory to 
implement, otherwise dma_buf_export() will fail to execute.

**为什么需要 attach 操作 ？**

同一个 dma-buf 可能会被多个 DMA 硬件访问，而每个 DMA 硬件可能会因为自身硬件能力
的限制，对这块 buffer 有自己特殊的要求。比如硬件 A 的寻址能力只有0x0 ~ 0x10000000，
而硬件 B 的寻址能力为 0x0 ~ 0x80000000，那么在分配 dma-buf 的物理内存时，就必须
以硬件 A 的能力为标准进行分配，这样硬件 A 和 B 都可以访问这段内存。否则，如果
只满足 B 的需求，那么 A 可能就无法访问超出 0x10000000 地址以外的内存空间，
道理其实类似于木桶理论。

因此，attach 操作可以让 exporter 驱动根据不同的 device 硬件能力，来分配最合适的
物理内存。

通过设置 device->dma_params 参数，来告知 exporter 驱动该 DMA 硬件的能力限制。

但是在上一篇的示例中，dma-buf 的物理内存都是在 dma_buf_export() 的时候就分配好的，
而 attach 操作只能在 export 之后才能执行，那我们如何确保已经分配好的内存是符合
硬件能力要求的呢？这就引出了下面的话题。

**何时分配内存？**

答案是：既可以在 export 阶段分配，也可以在 map attachment 阶段分配，甚至可以
在两个阶段都分配，这通常由 DMA 硬件能力来决定。

首先，驱动人员需要统计当前系统中都有哪些 DMA 硬件要访问 dma-buf；
然后，根据不同的 DMA 硬件能力，来决定在何时以及如何分配物理内存。

通常的策略如下（假设只有 A、B 两个硬件需要访问 dma-buf ）：

如果硬件 A 和 B 的寻址空间有交集，则在 export 阶段进行内存分配，分配时以 
A / B 的交集为准；
如果硬件 A 和 B 的寻址空间没有交集，则只能在 map attachment 阶段分配内存。
对于第二种策略，因为 A 和 B 的寻址空间没有交集（即完全独立），所以它们实际上是
无法实现内存共享的。此时的解决办法是： A 和 B 在 map attachment 阶段，都分配
各自的物理内存，然后通过 CPU 或 通用DMA 硬件，将 A 的 buffer 内容拷贝到 B 的 
buffer 中去，以此来间接的实现 buffer “共享”。

另外还有一种策略，就是不管三七二十一，先在 export 阶段分配好内存，然后在首次 
map attachment 阶段通过 dma_buf->attachments 链表，与所有 device 的能力进行
一一比对，如果满足条件则直接返回 sg_table；如果不满足条件，则重新分配符合所有 
device 要求的物理内存，再返回新的 sg_table。


## mmap

In order for applications to read and write dma-buf memory directly in 
user space, dma_buf_ops provides us with an mmap callback interface, 
which can directly map the physical memory of dma-buf to user space, 
so that applications can access ordinary files. Access the physical 
memory of dma-buf.

In addition to the mmap callback interface provided by dma_buf_ops, 
dma-buf also provides us with the dma_buf_mmap() kernel API, so that 
we can use local materials in other device drivers, directly refer to 
the mmap implementation of dma-buf, and indirectly realize Device 
driver's mmap file operation interface.


## dma-buf and file
from https://blog.csdn.net/hexiaolong2009/article/details/102596802

dma-buf is essentially a combination of buffer and file, not only that,
the file is also an opened file, and the file is also an anonymous file

**fd**

The following kernel API realizes the conversion between dma-buf and fd:
- dma_buf_fd()：dma-buf --> new fd
- dma_buf_get()：fd --> dma-buf


**get / put**

As long as it is a file, there will be a reference count (f_count) inside.
When using the dma_buf_export() function to create a dma-buf,
the reference count is initialized to 1; when the reference count is 0,
the release callback interface of dma_buf_ops will be automatically 
triggered and the dma-buf object will be released.


The commonly used functions for manipulating file reference counts 
in the linux kernel are fget() and fput(), and dma-buf encapsulates 
them on this basis, as follows:
- get_dma_buf()
- dma_buf_get()
- dma_buf_put()

function summary:
| function | description |
|----|----|
| get_dma_buf() | only adds 1 to the reference count |
| dma_buf_get() | adds 1 to the reference count and converts fd to a dma_buf pointer |
| dma_buf_put() | reference count minus 1 |
| dma_buf_fd()  | reference count unchanged, only fd created |


