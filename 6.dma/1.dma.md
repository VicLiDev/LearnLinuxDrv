# Dynamic DMA mapping Guide
reference:  
[Dynamic DMA mapping Guide](https://docs.kernel.org/core-api/dma-api-howto.html)  
[Dynamic DMA mapping using the generic device](https://docs.kernel.org/core-api/dma-api.html)  
[dma 和 cache的一致性](https://blog.csdn.net/Adrian503/article/details/115536886)

## CPU and DMA addresses

DMA API 涉及多种地址，了解它们之间的差异非常重要。

内核通常使用虚拟地址。类似kmalloc()和vmalloc()接口返回的地址都是虚拟地址，可以
存储在`void *`

虚拟内存系统（TLB、页表等）将虚拟地址转换为CPU物理地址，存储为“phys_addr_t”
或“resource_size_t”。内核可以通过设备树得知设备资源（如寄存器）的物理地址，
将设备资源（如寄存器）作为物理地址进行管理，可以在/proc/iomem 中查到。驱动
程序无法直接使用物理地址，必须用ioremap()映射空间并产生虚拟地址。
例如：
```
# cat /proc/iomem
...
22140800-2214083f : 22140800.iommu iommu@22140800
22140900-2214093f : 22140800.iommu iommu@22140800
...
```
这里内核可以从设备树得到的物理地址为：
```
22140800-2214083f
22140900-2214093f
```
对应的设备均为：
```
22140800.iommu iommu@22140800
22140800.iommu iommu@22140800
```

I/O 设备使用第三种地址：“总线地址”。如果设备在 MMIO（Memory-Mapped I/O，内存映射
输入/输出） 地址处有寄存器，或者执行 DMA 来读取或写入内存，则设备使用的地址是总线
地址。在某些系统中，总线地址与 CPU 物理地址相同，但通常情况不同。IOMMU 和主桥可以
在物理地址和总线地址之间生成映射（并不是所有的体系架构中都有IOMMU，特别是常见的
x86平台没有对IOMMU的支持）。

从设备的角度来看，DMA 使用总线地址空间，但它可能仅限于该空间的子集。例如，即使
系统支持64 位地址的主内存和 PCI BAR，但它可能使用 IOMMU，这时设备可能只需要使用
32 位 DMA 地址，这样使用的32为dma地址空间，就只是64位空间的一个子集。

这是一张图片和一些示例：
```
             CPU                  CPU                  Bus
           Virtual              Physical             Address
           Address              Address               Space
            Space                Space

          +-------+             +------+             +------+
          |       |             |MMIO  |   Offset    |      |
          |       |  Virtual    |Space |   applied   |      |
        C +-------+ --------> B +------+ ----------> +------+ A
          |       |  mapping    |      |   by host   |      |
+-----+   |       |             |      |   bridge    |      |   +--------+
|     |   |       |             +------+             |      |   |        |
| CPU |   |       |             | RAM  |             |      |   | Device |
|     |   |       |             |      |             |      |   |        |
+-----+   +-------+             +------+             +------+   +--------+
          |       |  Virtual    |Buffer|   Mapping   |      |
        X +-------+ --------> Y +------+ <---------- +------+ Z
          |       |  mapping    | RAM  |   by IOMMU
          |       |             |      |
          |       |             |      |
          +-------+             +------+
```

ioremap: C->B->A，最终目标是CPU读写设备上的寄存器
- map kernal virtual address space to cpu pyh address space
- map pyh addr to bus addr space by host birdge
- read/write bus addr space by kernel virtual address

dma_alloc_coherent: X->Y, Z->Y，最终目标是CPU/设备访问ddr
- map kernal virtual address space to cpu pyh address space
- map bus addr space to cpu pyh address space
- cpu read/write pyh space by kernel virtual address
- device driver config bus address to device, device read/write phy space by device bus address

内核了解 I/O 设备及其 MMIO 空间以及将它们连接到系统的主机桥。例如，如果 PCI 设备
有 BAR，则内核从 BAR 中读取总线地址（A）并将其转换为 CPU 物理地址（B）。地址 B
存储在结构资源中，通常通过 /proc/iomem 公开。当驱动程序声明一个设备时，它通常用于
ioremap()将物理地址 B 映射到虚拟地址（C）。然后，它可以使用 ioread32（C） 等来
访问总线地址 A 处的设备寄存器。

如果设备支持 DMA，驱动程序会使用或类似kmalloc()的接口设置缓冲区，该接口返回虚拟
地址 (X)。虚拟内存系统将 X 映射到系统 RAM 中的物理地址 (Y)。驱动程序可以使用虚拟
地址 X 来访问缓冲区，但设备本身不能，因为 DMA 不经过 CPU 虚拟内存系统。在一些简单
的系统中，设备可以直接对物理地址Y进行DMA。但在许多其他系统中，有IOMMU硬件将DMA
地址转换为物理地址，例如，它将Z转换为Y。这是部分DMA_API存在的原因：驱动程序可以
向 dma_map_single() 等接口提供虚拟地址 X，该接口完成 IOMMU 映射并返回 DMA 地址 Z。
然后驱动程序告诉设备对 Z 执行 DMA 操作。

注意，DMA API 可与独立于底层微处理器架构的任何总线配合使用。即使在不存在相关硬件
的平台上，DMA API 也可以工作。应该使用 DMA API 而不是总线特定的 DMA API，即使用
`dma_map_*()` 接口而不是 `pci_map_*()` 接口。

首先，应该确保`#include <linux/dma-mapping.h>`，在驱动程序中，它提供了 dma_addr_t
的定义。dma_addr_t 可以保存DMA地址，该地址配置到设备中，作为DMA搬运数据时的源地址
或者目的地址。

## ARM 架构常见 DMA 硬件拓扑
![frame work](./imgs/1.png)

reference:  
[Linux DMA 简介](https://blog.csdn.net/JiMoKuangXiangQu/article/details/131351198?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-131351198-blog-79462064.235%5Ev38%5Epc_relevant_sort_base3&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-131351198-blog-79462064.235%5Ev38%5Epc_relevant_sort_base3&utm_relevant_index=1)

## 缓存一致性问题存在原因

在描述缓存一致性的时候，通常认为存在如下结构：
```
                  +------+
                  |MMIO  |
                  |Space | +------+
                  +------+ |      |
                  |      | | Dev0 |
+-----+ +-------+ |      | |      |
|     | |       | +------+ +------+
| CPU | | cache | | RAM  |
|     | |       | |      | +------+
+-----+ +-------+ +------+ |      |
                  |Buffer| | Dev0 |
                  +------+ |      |
                  | RAM  | +------+
                  |      |
                  +------+
```
但也有按照下图理解的结构，这并不作为主流，因此这里的讨论以上边的结构为基准
```
                  +------+
                  |MMIO  |
                  |Space | +-------+ +------+
                  +------+ |       | |      |
                  |      | | cache | | Dev0 |
+-----+ +-------+ |      | |       | |      |
|     | |       | +------+ +-------+ +------+
| CPU | | cache | | RAM  |
|     | |       | |      | +-------+ +------+
+-----+ +-------+ +------+ |       | |      |
                  |Buffer| | cache | | Dev0 |
                  +------+ |       | |      |
                  | RAM  | +-------+ +------+
                  |      |
                  +------+
```


该问题的解决方法：
1. 基于硬件的解决方案：这样的系统是一致性系统
2. 基于软件的解决方案：操作系统负责确保缓存一致性。这样的系统称作非一致性系统。  
   (包括：一致性DMA映射和流式DMA映射)


工程中一般有两种情况，会导致 cache的不一致性，不过kernel都有对应的机制。

1. 操作寄存器地址空间。  
寄存器是CPU与外设交流的接口，有些状态寄存器是由外设根据自身状态进行改变。有可能
这次CPU读入该状态寄存器，下次再读时，该状态寄存器已经变了，但是CPU还是读取的cache
中缓存的值。但是寄存器操作在kernel中是必须保证一致的，这是kernel控制外设的基础，
IO空间通过ioremap进行映射到内核空间。ioremap在映射寄存器地址时页表是配置为uncached
的。数据不走cache，直接由地址空间中读取。保证了数据一致性。  
这种情况kernel已经保证了data的一致性，应用场景简单。

2. DMA申请的内存空间。  
DMA操作对于CPU来说也是不透明的，DMA导致内存中数据更新，对于CPU来说是完全不可见的。
反之亦然，CPU写入数据到DMA缓冲区，其实是写到了cache，这时启动DMA，操作DDR中的数据
并不是CPU真正想要操作的。这种情况是，CPU 和DMA 都可以异步的对mem 进行操作，导致
data不一致性。  
对于cpu 和 dma 都能访问的mem ，kernel有专业的管理方式，分为两种：  
a. 给DMA申请的内存，禁用 cache ，当然这个是最简单的，不过性能方面是有影响的。(一致性DMA映射)  
b. 使用过程中，通过flush cache / invalid cache 来保证data 一致性。（流式DMA映射）

## 哪些内存可以使用DMA？
本节尝试描述哪些内核内存可以使用 DMA 映射工具。

如果通过页面分配器（即`__get_free_page*()`）或通用内存分配器（即`kmem_cache_alloc()`
或`kmalloc()`）获取内存，那么这些地址可以用于 DMA 传输。

使用vmalloc()意味着可能不会将其返回的地址用于 DMA。DMA 或许可以理解 vmalloc()
返回的内存区域，但这需要遍历页表来获取物理地址，然后使用 __va() 之类的方法将每个
页面转换回内核地址。
[编辑：当我们集成执行此操作的 Gerd Knorr 通用代码时更新此内容。]

另外，既不能使用内核映像地址（数据/文本/bss 段中的项目），也不能使用模块映像地址，
也不能使用 DMA 的堆栈地址。这些都可以映射到随机的物理内存区域。即使这些类别的内存
在物理上可以与 DMA 配合使用，也需要确保 I/O 缓冲区是缓存行对齐的。否则，会在具有
DMA 非一致性缓存的 CPU 上看到缓存行共享问题（数据损坏）。（CPU 可以写入一个字，
DMA 可以写入同一缓存行中的另一个字，并且其中一个字可以被覆盖。）

此外，无法调用 kmap() 进行 DMA 操作。这类似于vmalloc()。

在一个系统中，DMA的使用限制还与外设的寻址能力有关，并不是所有的内存区间都适合DMA
操作。在实际场景下，有一些设备和一些系统中的高端内存不能用于DMA，这是因为外设不能
使用高端内存的地址，即寻址能力的限制，具体见下一节描述。

现代总线上的大多数设备能够处理32位地址，这意味着常用的内存分配机制能很好的工作。
一些PCI设备没能实现

对于有这些限制的设备，应该使用 GFP_DMA 标志调用 kmalloc 或者 get_free_pages 分配
DMA 内存。当设置了该标志时，才能分配到只使用24位寻址方式的内存。

## DMA 寻址能力(mask)

设置寻址能力主要是告诉内核，当前外设的寻址能力，以保证内核行为正常。

**默认情况下，内核假定您的设备可以寻址 32 位 DMA 寻址。** 对于支持 64 位的设备，
需要增加该值，对于有限制的设备，需要减少该值。

关于 PCI 的特别说明：PCI-X 规范要求 PCI-X 设备支持所有事务的 64 位寻址 (DAC)。
并且至少有一个平台（SGI SN2）需要 64 位一致分配才能在 IO 总线处于 PCI-X 模式时
正确运行。

**为了正确操作，必须设置 DMA 掩码以告知内核您的设备 DMA 寻址功能。除非设备支持
常见的32位DMA操作，则没有必要调用 dma_set_mask。**

可以通过调用 dma_set_mask_and_coherent() 设置掩码的：
```c
int dma_set_mask_and_coherent(struct device *dev, u64 mask);
```
这为流式 API 和一致性 API 一起设置掩码。如果有一些特殊要求，则可以使用以下两个
单独的调用来代替：

流映射通过调用 dma_set_mask() 实现：
```c
int dma_set_mask(struct device *dev, u64 mask);
```
一致分配通过调用 dma_set_coherent_mask() 实现：
```c
int dma_set_coherent_mask(struct device *dev, u64 mask);
```
这里，dev 是指向设备结构体的指针，mask 是描述设备支持地址的位掩码。通常，设备结构
嵌入在相关结构体中。例如，&pdev->dev 。

这些调用通常返回零，表示当前设备可以依据给定的地址掩码，在当前设备上正确执行 DMA，
但如果掩码太小而无法在给定系统上支持，则它们可能会返回错误。如果它返回非零，则当前
设备无法在此平台上正确执行 DMA，并且尝试这样做将导致未定义的行为。除非
dma_set_mask 函数系列返回成功，否则不得在此设备上使用 DMA。

这意味着在失败的情况下，您有两种选择：
1. 如果可能，请使用某种非 DMA 模式进行数据传输。
2. 忽略该设备并且不对其进行初始化。

建议驱动程序在设置 DMA 掩码失败时打印内核 KERN_WARNING 消息。

标准 64 位寻址设备会执行以下操作：
```c
if (dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64))) {
        dev_warn(dev, "mydev: No suitable DMA available\n");
        goto ignore_this_device;
}
```
如果设备仅支持一致分配中描述符的 32 位寻址，但支持流映射的完整 64 位，则它将如下
所示：
```c
if (dma_set_mask(dev, DMA_BIT_MASK(64))) {
        dev_warn(dev, "mydev: No suitable DMA available\n");
        goto ignore_this_device;
}
```
一致性掩码始终能够设置与流掩码相同或更小的掩码。对于设备驱动程序仅使用一致分配
的罕见情况，必须检查 dma_set_coherent_mask() 的返回值。

最后，如果设备只能驱动地址的低 24 位，可能需要执行以下操作：
```c
if (dma_set_mask(dev, DMA_BIT_MASK(24))) {
        dev_warn(dev, "mydev: 24-bit DMA addressing not available\n");
        goto ignore_this_device;
}
```
当 dma_set_mask() 或 dma_set_mask_and_coherent() 成功并返回零时，内核会保存提供
的此掩码。稍后当进行 DMA 映射时，内核将使用此信息。

目前我们知道一个案例，如果您的设备支持多种功能（例如声卡提供播放和录音功能），
并且各种不同的功能具有不同的 DMA 寻址限制，您可能希望探测每个掩码并仅提供机器可以
处理的功能。重要的是，最后一次调用 dma_set_mask() 是针对最具体的掩码。

这是显示如何完成此操作的伪代码：
```c
#define PLAYBACK_ADDRESS_BITS   DMA_BIT_MASK(32)
#define RECORD_ADDRESS_BITS     DMA_BIT_MASK(24)

struct my_sound_card *card;
struct device *dev;

...
if (!dma_set_mask(dev, PLAYBACK_ADDRESS_BITS)) {
        card->playback_enabled = 1;
} else {
        card->playback_enabled = 0;
        dev_warn(dev, "%s: Playback disabled due to DMA limitations\n",
               card->name);
}
if (!dma_set_mask(dev, RECORD_ADDRESS_BITS)) {
        card->record_enabled = 1;
} else {
        card->record_enabled = 0;
        dev_warn(dev, "%s: Record disabled due to DMA limitations\n",
               card->name);
}
```
这里以声卡为例，因为这种 PCI 设备在 PCI 前端的情况下似乎散布着 ISA 芯片，因此
保留了 ISA 的 16MB DMA 寻址限制。

该 API 返回平台高效运行所需的掩码。通常这意味着返回的掩码是覆盖所有内存所需的
最小值。检查所需的掩码使具有可变描述符大小的驱动程序有机会根据需要使用较小的
描述符。
```c
u64 dma_get_required_mask(struct device *dev)
// 请求所需的掩码不会改变当前掩码。如果您希望利用它，您应该调用 dma_set_mask() 以将掩码
// 设置为返回的值。
```

返回设备映射的最大大小。dma_map_single()、dma_map_page() 等映射函数的大小参数不应
大于该接口的返回值。
```c
size_t dma_max_mapping_size(struct device *dev);
```
返回设备映射的最大最佳大小。
```c
size_t dma_opt_mapping_size(struct device *dev);
```
在某些情况下，映射较大的缓冲区可能需要更长的时间。此外，对于高速率、短生命期的
流映射，花费在映射上的前期时间可能占总请求生命周期的很大一部分。因此，如果拆分
较大的请求不会导致显着的性能损失，则建议设备驱动程序将总 DMA 流映射长度限制为
返回值。

确认是否需要调用 dma_sync_single_for_{device,cpu} 来转移内存所有权，如果需要则
返回 %true。如果可以跳过这些调用，则返回 %false。
```c
bool dma_need_sync(struct device *dev, dma_addr_t dma_addr);
```

返回 DMA 合并边界。如果设备无法合并任何 DMA 地址段，则该函数返回 0。
```c
unsigned long dma_get_merge_boundary(struct device *dev);
```

## DMA 映射分类

DMA 映射有两种类型： 一致性DMA映射、流式DMA映射（分为单缓冲区映射和分散/聚集映射）
此外，区别于一致性DMA映射、流式DMA映射，还有一种非一致性映射

**一致性DMA（Coherent DMA）的特点：**
1. 一致性保证：一致性DMA确保数据的传输和存储在系统的各个组件（如CPU、DMA控制器、
缓存等）之间是一致的，避免了由于数据不一致而导致的错误或异常。
2. 适用于共享内存系统：在多处理器系统或者多核系统中，一致性DMA能够确保各个处理
器/核心之间共享的数据是一致的，从而提高系统的稳定性和可靠性。
3. 增强的数据一致性：一致性DMA通常配合硬件机制（如缓存一致性协议）来实现数据的
一致性，从而避免了软件层面对数据一致性进行额外的管理。
4. 相对复杂：与流式DMA相比，一致性DMA通常需要更多的硬件支持和复杂的实现，因此在
设计和开发过程中可能会增加一定的成本和复杂度。


**流式DMA（Direct Memory Access）的特点：**
1. 非连续性：流式DMA不需要保证数据传输的顺序，可以通过一次性传输数据块到目的地。
这使得流式DMA适用于需要高效率传输大量数据的场景，如视频处理、网络数据传输等。
2. 无需CPU介入：在流式DMA中，数据传输过程中不需要CPU的参与，CPU可以继续执行其他
任务，从而提高系统整体的效率。
3. 数据流模式：流式DMA通常采用流水线模式，可以实现数据的连续传输，从而实现高效的
数据流处理。
4. 适用于并行处理：由于流式DMA可以在数据传输过程中实现并行处理，因此非常适合需要
高并发处理的应用场景。

总的来说，流式DMA适用于需要高效率传输大量数据的场景，而一致性DMA适用于需要保证数据
一致性和稳定性的共享内存系统中。在实际应用中，根据具体的需求和系统架构选择合适的
DMA传输方式非常重要。


**除了流式DMA和一致性DMA之外，还有一些其他类型的DMA，其中一些主要特点如下：**
1. 循环DMA（Circular DMA）：循环DMA可以在数据传输完成后重新开始传输，而不需要重新
配置DMA控制器。这种DMA类型通常用于连续性的数据传输，例如音频流或视频流。
2. 串行DMA（Serial DMA）：串行DMA是一种用于在串行总线上进行数据传输的DMA，通常用于
与外部设备（如串行接口设备或存储设备）进行通信。
3. 散列DMA（Scatter-Gather DMA）：散列DMA允许DMA控制器在内存中的多个散布的位置进行
数据传输，而不是连续的内存块。这种DMA类型对于处理分散存储的数据结构或者需要从多个
源读取数据的情况非常有用。
4. 同步DMA（Synchronous DMA）：同步DMA是一种需要与外部设备进行同步操作的DMA，通常
与外部设备的时钟信号或其他同步信号进行同步，以确保数据传输的时序和稳定性。
5. 自适应DMA（Adaptive DMA）：自适应DMA具有自适应性，可以根据当前系统负载或其他
因素自动调整传输参数，以提高系统的性能或稳定性。

这些不同类型的DMA适用于不同的应用场景，并且在设计和实现中可能会有一些特定的硬件
或软件要求。选择合适的DMA类型取决于系统的需求以及对性能、稳定性和灵活性的考虑。


### 一致性DMA映射

一致的 DMA 映射通常在驱动程序初始化时映射，在结束时取消映射，为此硬件应保证设备
和 CPU 可以并行访问数据，并且会看到彼此进行的更新，而无需任何显式软件刷新。即
`一致性dma`不需要考虑缓存一致性，会在内部将缓存问题处理好，对于设备生命周期一直
存在的buffer，建议使用这种缓存。

dma_alloc_coherent首先对分配到的缓冲区进行cache刷新，之后将该缓冲区的页表修改为
uncached，以此来保证之后DMA与CPU操作该块数据的一致性。对于通常的硬件平台（不带
硬件cache 一致性的组件），dma_alloc_coherent 内存操作，CPU 直接操作内存，没有
cache 参与。但是也有例外，有的CPU 很强，dma_alloc_coherent 也是可以申请到 带
cache的内存的。有些SoC可以用硬件做CPU和外设的cache coherence，例如在SoC中集成了
叫做“Cache Coherent interconnect”的硬件，它可以做到让DMA踏到CPU的cache或者帮忙
做cache的刷新。这样的话，dma_alloc_coherent()申请的内存就没必要是非cache的了。
**在思维上，一定要想到 dma_alloc_coherent 的接口，只是一个前端，它具体的实现是和
硬件平台有关系的。**
```

+--------------------+
| +------+ +-------+ |     +--------------+
| | CPU  | | L1    | |     |              |     +--------+
| | Core | | Cache | |     |              | <-- | Device |
| +------+ +-------+ |     |              |     +--------+
| +----------------+ |     | Cache        |
| | L2 Cache       | |     | Coherent     |
| +----------------+ |     | Interconnect |
| +------+ +-------+ |     |              |     +------------+     +--------+
| | CPU  | | L1    | | <-- |              | <-- | Memory     | <-- | Memory |
| | Core | | Cache | |     |              |     | Controller |     +--------+
| +------+ +-------+ |     +--------------+     +------------+
+--------------------+
```

将“一致”视为“同步”或“一致”。

当前默认是在 DMA 空间的低 32 位中返回一致的内存。但是，为了将来的兼容性，即使此
默认值适合您的驱动程序，也应该设置一致的掩码。

使用一致映射的比较好的例子是：
1. 网卡 DMA 环描述符。
2. SCSI 适配器邮箱命令数据结构。
3. 在主存储器外执行的设备固件微代码。

这些示例都要求的是，任何 CPU 存储到内存的操作都对设备立即可见，反之亦然。一致的
映射保证了这一点。
```
重要：
一致的 DMA 内存并不排除使用适当的内存屏障。CPU 可以将存储重新排序到一致内存，它
可以像正常内存一样。示例：如果设备在第二个字之前看到描述符的第一个字更新很重要，
则必须执行以下操作：

desc->word0 = address;
wmb();
desc->word1 = DESC_VALID;
为了在所有平台上获得正确的行为。

此外，在某些平台上，驱动程序可能需要以与刷新 PCI 桥中的写入缓冲区大致相同的方式
刷新 CPU 写入缓冲区（例如，在写入寄存器的值后读取该值）。
```

#### 使用方法

要分配和映射大的（PAGE_SIZE 左右）一致的 DMA 区域，您应该执行以下操作：
```c
dma_addr_t dma_handle;

cpu_addr = dma_alloc_coherent(dev, size, &dma_handle, gfp);
// 这可以在中断上下文中使用 GFP_ATOMIC 标志来调用。
// 申请的buffer物理上是连续的
// Size 是要分配的区域的长度（以字节为单位）。
// 该接口可以分配的最小内存是, 一个页面，总的页面数量只能是2次幂。
// 该接口的作用与 __get_free_pages() 类似（但采用size而不是页面号）。
// 注意：一致性内存在某些平台上可能会很昂贵，并且最小分配长度可能与页面一样大，
// 因此您应该尽可能合并对一致性内存的请求。
// 如果您的驱动程序需要大小小于页面的区域，dma_pool 接口会更适合，如下所述。

// dma_alloc_coherent() 返回两个值：可用于从 CPU 访问它的虚拟地址和传递给设备的 dma_handle。
// CPU 虚拟地址和 DMA 地址都保证与大于或等于请求大小的最小 PAGE_SIZE 顺序对齐。
// 这是为了保证如果分配小于或等于 64 KB 的块，则您接收的缓冲区范围不会跨越 64K 边界。
```

要取消映射并释放此类 DMA 区域，可以调用：
```c
dma_free_coherent(dev, size, cpu_addr, dma_handle);
// 其中 dev、size 与上面的调用相同，cpu_addr 和 dma_handle 是 dma_alloc_coherent()
// 返回的值。该函数不能在中断上下文中调用。
```

如果驱动程序需要大量较小的内存区域，可以自己编写代码来细分 dma_alloc_coherent()
返回的页面，或者可以使用 dma_pool API 来执行此操作。dma_pool 类似于 kmem_cache，
但它使用dma_alloc_coherent() 实现，而不是 __get_free_pages()。此外，它还满足对齐
的常见硬件约束，例如队列头需要在 N 字节边界上对齐。

使用这部分的 dma_API，必须包含头文件：`#include <linux/dmapool.h>`

创建 dma_pool：
```c
struct dma_pool *pool;

pool = dma_pool_create(name, dev, size, align, boundary);

// dma_pool_create() 初始化 DMA 一致缓冲区池以供给定设备使用。它必须在可以睡眠的上下文中调用。
// “name”用于诊断，dev 和 size 如上。
// 设备对此类数据的硬件对齐要求是“align”（以字节表示，并且必须是2的幂）。
// 如果你的设备没有边界穿越限制，则为 alloc 传递 0；传递 4096 表示从该池分配的内存不得跨越
// 4KByte 边界（但此时直接使用 dma_alloc_coherent() 可能更好）。
```

从 DMA 池中分配内存，如下所示：
```c
cpu_addr = dma_pool_alloc(pool, flags, &dma_handle);
// 这会从池中分配内存，返回的内存将满足创建时指定的大小和对齐要求
// 传递 GFP_ATOMIC 以防止阻塞
// 如果允许阻塞（不允许 in_interrupt 或持有 SMP 锁），则标志为 GFP_KERNEL
// 否则为 GFP_ATOMIC。
// 与 dma_alloc_coherent() 类似，它返回两个值：cpu_addr 和 dma_handle（总线地址）。

void *
dma_pool_zalloc(struct dma_pool *pool, gfp_t mem_flags,
                dma_addr_t *handle)
// dma_pool_zalloc()如果分配尝试成功，则返回内存地址，内存空间被清零。
```

释放从 dma pool 分配的内存如下：
```c
dma_pool_free(pool, cpu_addr, dma_handle);
// cpu_addr 和 dma_handle 是dma_pool_alloc()返回的值。该函数可以在中断上下文中调用。
// 将内存放回池中。它必须在可以睡眠的上下文中调用。 (这里两个kernel文档有冲突，后续查证更新)
```

通过调用以下命令销毁 dma_pool：
```c
dma_pool_destroy(pool);
// 在销毁pool之前需要调用dma_pool_free() 释放从pool中分配的所有内存。
// 该函数不能在中断上下文中调用。
```

另外，DMA还提供了写合并相关的接口（具体含义待后续完善）：
```c
static inline void *dma_alloc_wc(struct device *dev, size_t size,
				 dma_addr_t *dma_addr, gfp_t gfp)


static inline void dma_free_wc(struct device *dev, size_t size,
			       void *cpu_addr, dma_addr_t dma_addr)

```

### 流式 DMA 映射

流 DMA 映射，通常针对一次 DMA 传输进行映射，在数据传输完成之后立即取消映射。为了
节省系统资源，应该尽量使用流式DMA映射。

将“流”视为“异步”或“在一致性域之外”。

流式DMA存在以下特点：
* 映射需要使用已分配的缓冲区
* 映射可以接受几个分散的不连续区域
* 需要特别注意数据操作时的一致性问题
* 必须指定数据的移动方向，而且只能基于该方向进行数据传输

使用流映射的比较好的例子是：
1. 设备发送/接收的网络缓冲区。
2. 文件系统缓冲区由 SCSI 设备写入/读取。

使用此类映射的接口的设计方式使得实现可以进行硬件允许的任何性能优化。为此，在使用
此类映射时，必须明确当前需求的场景。

两种类型的 DMA 映射都没有来自底层总线的对齐限制，尽管某些设备可能有此类限制。此外，
当底层缓冲区不与其他数据共享缓存行时，具有非 DMA 一致性缓存的系统将工作得更好。


#### DMA Direction
只有流映射指定方向，一致映射隐式具有 DMA_BIDIRECTIONAL 方向属性设置，DMA 方向参数
是一个整数并采用以下值之一：
```c
enum dma_data_direction {
  DMA_BIDIRECTIONAL = 0,
  DMA_TO_DEVICE = 1,
  DMA_FROM_DEVICE = 2,
  DMA_NONE = 3,
};

// mem <-> dev-mem
// mem -> dev-mem
// dev-mem -> mem

// DMA_TO_DEVICE 表示从主存到设备: 
//   在将该参数配置给设备之前，必须将`驱动`最后一次修改同步到内存中，以避免cache引入
//   同步问题。一旦使用该配置，对于`设备`而言，对应的内存被视为只读。
// DMA_FROM_DEVICE 表示从设备到主存：
//   在将该参数配置给设备之前，必须将`设备`最后一次修改同步到内存中，以避免cache引入
//   同步问题。一旦使用该配置，对于`驱动`而言，对应的内存应该被视为只读。
// DMA_BIDIRECTIONAL 表示传输可以朝任一方向进行：
//   需要特殊处理：这意味着驱动程序不确定内存在移交给设备之前是否被修改，也不确定设备
//   是否也会修改它。因此，必须始终同步双向内存两次：一次在内存移交给设备之前（以确保
//   所有内存更改都从cache中flush），一次在设备使用数据后可以访问数据之前。确保所有
//   处理器缓存行都使用设备可能已更改的数据进行更新）。
// 如果绝对无法知道 DMA 传输的方向，指定 DMA_BIDIRECTIONAL，这可能会以性能为代价

// DMA_NONE 用于调试。在知道精确方向之前，可以将其保存在数据结构中，
// 这将有助于捕获方向跟踪未能正确设置的情况。
```
如果知道的话，应该提供准确的 DMA 方向。

精确指定该值的另一个优点（除了潜在的特定于平台的优化之外）是为了调试。有些平台实际上
有一个写权限布尔值，可以用它来标记 DMA 映射，就像用户程序地址空间中的页面保护一样。
当 DMA 控制器硬件检测到违反权限设置时，此类平台会在内核日志中报告错误。

SCSI 子系统告诉驱动程序正在处理的 SCSI 命令的“sc_data_direction”成员中使用的方向。

对于网络驱动程序来说，这是一件相当简单的事情。对于传输数据包，使用 DMA_TO_DEVICE
方向说明符映射/取消映射。对于接收数据包，恰恰相反，使用 DMA_FROM_DEVICE 方向说明
符映射/取消映射。

#### 使用

流 DMA 映射例程可以从中断上下文中调用。每个映射/取消映射都有两个版本:
* 映射/取消映射 单个内存区域，只允许单页映射
* 映射/取消映射 散列表，允许传递多个内存区域（分散在内存中）

##### 映射单个内存区域

映射单个内存区域：
```c
struct device *dev = &my_dev->dev;
dma_addr_t dma_handle;
void *addr = buffer->ptr;
size_t size = buffer->len;

dma_handle = dma_map_single(dev, addr, size, direction);
if (dma_mapping_error(dev, dma_handle)) {
        /*
         * reduce current DMA mapping usage,
         * delay and try again later or
         * reset driver.
         */
        goto map_error_handling;
}
// 注意：
// 并非所有内存区域都可以通过此 API 映射。另外，连续的内核虚拟空间可能不像物理内存
// 那样连续。由于此 API 不提供任何分散/聚集功能，因此如果用户尝试映射非物理连续的
// 内存片段，它将失败。因此，此 API 映射的内存应从保证其物理连续的来源（如 kmalloc）获取。

// 此外，存储器的 DMA 地址必须在设备的 dma_mask 范围内（dma_mask 是设备可寻址区域
// 的位掩码，即，如果存储器的 DMA 地址与 dma_mask 进行 AND 运算后仍然等于 DMA地址，
// 然后设备可以对内存执行 DMA）。为了确保 kmalloc 分配的内存在 dma_mask 内，驱动程序
// 可以指定各种与平台相关的标志来限制分配的 DMA 地址范围（例如，在 x86 上，根据 ISA 设备
// 的要求，GFP_DMA 保证位于可用 DMA 地址的前 16MB 内）。

// 另请注意，如果平台具有 IOMMU（将 I/O DMA 地址映射到物理内存地址的设备），则上述
// 对物理连续性和 dma_mask 的限制可能不适用。然而，为了便于移植，设备驱动程序编写者
// 可能不会假设存在这样的 IOMMU。
```
调用 dma_mapping_error()很有必要，因为 dma_map_single() 可能会失败并返回错误。
这同样适用于 dma_map_page()。


当 DMA 使用结束后，您应该调用 dma_unmap_single()，例如，从通知您 DMA 传输已完成的
中断中调用 dma_unmap_single()，取消映射：
```c
dma_unmap_single(dev, dma_handle, size, direction);
```

像这样对单个映射使用 CPU 指针（虚拟地址）有一个缺点：无法以这种方式引用 HIGHMEM
内存。因此，存在类似于 dma_{map,unmap}_single() 的映射/取消映射接口。这些接口使用
页/偏移量而不是 CPU 指针（虚拟地址）。这里，“偏移量”是指给定页面内的字节偏移量。
以下接口用于页面映射和取消映射。其他映射 API 的所有注释和警告均适用于此处。另外，
虽然提供了 <offset> 和 <size> 参数来进行部分页面映射，但建议您永远不要使用这些
参数，除非您确实知道缓存宽度是多少。具体来说：
```c
struct device *dev = &my_dev->dev;
dma_addr_t dma_handle;
struct page *page = buffer->page;
unsigned long offset = buffer->offset;
size_t size = buffer->len;

dma_handle = dma_map_page(dev, page, offset, size, direction);
if (dma_mapping_error(dev, dma_handle)) {
        /*
         * reduce current DMA mapping usage,
         * delay and try again later or
         * reset driver.
         */
        goto map_error_handling;
}

...

dma_unmap_page(dev, dma_handle, size, direction);
```
同样应该调用 dma_mapping_error()，因为 dma_map_page() 可能会失败并返回错误，
如 dma_map_single() 讨论中所述。

当 DMA 使用结束后，应该调用 dma_unmap_page()，例如，从通知您 DMA 传输已完成的中断
中调用。


以下是用于映射和取消映射 MMIO 资源的 API。其他映射 API 的所有注释和警告均适用于
此处。该 API 只能用于映射设备 MMIO 资源，不允许映射 RAM。
```c
dma_addr_t
dma_map_resource(struct device *dev, phys_addr_t phys_addr, size_t size,
                 enum dma_data_direction dir, unsigned long attrs)

void
dma_unmap_resource(struct device *dev, dma_addr_t addr, size_t size,
                   enum dma_data_direction dir, unsigned long attrs)
```


##### 映射散列表

在使用IOMMU的情况下，修改映射寄存器后，可以使得SG（散列表）中分段的缓冲区地址对
外设变得连续，（个人理解：动物书上讲，散列表需要设备支持，但我认如果存在IOMMU使
设备能够访问连续空间也是可以的，换句话说，要不设备能自己处理散列表，要不通过
IOMMU将三列表转换成连续地址，都可以使设备正常工作），使用散列表，可以通过以下
方式映射从多个来源收集的区域：
```c
int i, count;
u32 *buf[BUF_CNT];
struct scatterlist sglist[BUF_CNT], *sg;

for (i = 0; i < BUF_CNT; i++)
        buf[i] = kzalloc(BUF_SIZE, GFP_DMA);

sg_init_table(sglist, BUF_CNT)
for (i = 0; i < BUF_CNT; i++)
        sg_set_buf(&sglist[i], buf, SDMA_BUF_SIZE);

count = dma_map_sg(dev, sglist, nents, direction);

for_each_sg(sglist, sg, count, i) {
        hw_address[i] = sg_dma_address(sg);
        hw_len[i] = sg_dma_len(sg);
}
// 其中 nents 是 sglist 中的条目数。
// 返回映射的 DMA 地址段的数量（如果分散/聚集列表的某些元素物理或虚拟相邻并且 IOMMU
// 使用单个条目映射它们，则这可能比传入的 nents 短）。
```
该实现可以自由地将多个连续的 sglist 条目合并为一个（例如，使用 IOMMU，或者如果
多个页面恰好是物理上连续的 - 事实上，这是对于不能进行分散收集或分散收集条目数量
非常有限的卡来说，这是一个巨大的优势）并返回其映射到的 sg 条目的实际数量。失败时
返回 0。并且驱动程序必须采取适当的措施。驱动程序执行某些操作至关重要，在块驱动
程序中止请求甚至 oopsing 的情况下，总比不执行任何操作并损坏文件系统要好。

然后，应该循环 count 次（注意：这可能小于 nents 次），并在访问 sg->address 和
sg->length 的位置使用 sg_dma_address() 和 sg_dma_len() 宏，如上所示。

要取消映射分散列表，只需调用：
```c
dma_unmap_sg(dev, sglist, nents, direction);
// 注意
// dma_unmap_sg 调用的“nents”参数必须与您传递到 dma_map_sg 调用中的参数相同，
// 它不应该是从 dma_map_sg 调用返回的“count”值。
```

#### 带 attrs 的映射

```c
dma_addr_t
dma_map_single_attrs(struct device *dev, void *cpu_addr, size_t size,
                     enum dma_data_direction dir,
                     unsigned long attrs)

void
dma_unmap_single_attrs(struct device *dev, dma_addr_t dma_addr,
                       size_t size, enum dma_data_direction dir,
                       unsigned long attrs)

int
dma_map_sg_attrs(struct device *dev, struct scatterlist *sgl,
                 int nents, enum dma_data_direction dir,
                 unsigned long attrs)

void
dma_unmap_sg_attrs(struct device *dev, struct scatterlist *sgl,
                   int nents, enum dma_data_direction dir,
                   unsigned long attrs)
```
上面的四个函数与不带 _attrs 后缀的对应函数类似，只是它们传递了可选的 dma_attrs。

DMA 属性的解释是特定于体系结构的，每个属性都应记录在 
[DMA 属性](https://docs.kernel.org/core-api/dma-attributes.html) 中。

如果 dma_attrs 为 0，则每个函数的语义与不带 _attrs 后缀的相应函数的语义相同。
因此 dma_map_single_attrs() 一般可以替代 dma_map_single() 等。

作为*_attrs函数使用的示例，以下是在映射 DMA 内存时如何传递属性 DMA_ATTR_FOO：
```c
#include <linux/dma-mapping.h>
/* DMA_ATTR_FOO should be defined in linux/dma-mapping.h and
* documented in Documentation/core-api/dma-attributes.rst */
...

        unsigned long attr;
        attr |= DMA_ATTR_FOO;
        ....
        n = dma_map_sg_attrs(dev, sg, nents, DMA_TO_DEVICE, attr);
        ....
```

关心 DMA_ATTR_FOO 的架构将检查其在映射和取消映射例程的实现中是否存在，例如：
```c
void whizco_dma_map_sg_attrs(struct device *dev, dma_addr_t dma_addr,
                             size_t size, enum dma_data_direction dir,
                             unsigned long attrs)
{
        ....
        if (attrs & DMA_ATTR_FOO)
                /* twizzle the frobnozzle */
        ....
}
```

#### 数据同步(cache 一致性)

数据同步即cache一致性问题，通常认为一旦缓冲区被映射，它将属于设备，而不是处理器，
因此直到取消映射之前，驱动程序不能以任何方式访问其中的内容。只有当取消映射之后，
驱动程序才能安全访问DMA缓冲区中的内容，这意味着在进行映射之前需要将要传输的数据
都写入DMA中，且写入完成。即便如此，仍然可能存在映射期间需要访问数据的场景，这也
是这一节中描述的内容。

每个 dma_map_{single,sg}() 调用都应该有其 dma_unmap_{single,sg}() 对应项，
因为 DMA 地址空间是共享资源，不及时释放可能会导致消耗所有 DMA 地址而导致机器不可用。

如果需要多次使用相同的流 DMA 区域并在 DMA 传输之间接触数据，则需要正确同步缓冲区，
以便 CPU 和设备能够看到最新且正确的数据副本。同步过程同时意味着DMA所有权的转移。

在使用 dma_map_{single,sg}() 进行映射后，如果CPU需要访问缓存，需要在每次 DMA 传输
调用之后，同步数据，将数据从内存更新到 cache，DMA所有权传递给CPU：
```c
// 将单个DMA缓冲区的内存数据与CPU的缓存进行同步。
dma_sync_single_for_cpu(dev, dma_handle, size, direction);
// 或：
// 与上述函数类似，但是适用于散列列表（Scatter-Gather List，SG）中的多个DMA缓冲区。
// 散列列表允许将多个分散的物理内存区域组合成一个逻辑的连续内存空间，这在一些情况下
// 会提高DMA传输的效率。这个函数用于将整个散列列表中的内存数据与CPU的缓存进行同步。
dma_sync_sg_for_cpu(dev, sglist, nents, direction);
```

如果希望让设备再次访问 DMA 区域，需要在 CPU 对数据的访问后，在将缓冲区提供给硬件
调用之前，同步数据, 将数据从 cache 回写到内存，DMA所有权归还给设备：
```c
// 将单个DMA缓冲区的内存数据与设备的缓存进行同步。在进行DMA操作之后，必须确保设备可以
// 访问到最新的数据，以免出现数据不一致性。这个函数用于将CPU缓存中的数据同步到设备的
// 缓存中。
dma_sync_single_for_device(dev, dma_handle, size, direction);
// 或：
// 与上述函数类似，但是适用于散列列表中的多个DMA缓冲区。将整个散列列表中的内存数据
// 与设备的缓存进行同步，以确保设备可以访问到最新的数据。
dma_sync_sg_for_device(dev, sglist, nents, direction);
```
因此一个常规的cpu访问dma区域的cache操作为：
```C
dma_sync_{single/sg}_for_cpu()
// cpu read/write
dma_sync_{single/sg}_for_device()
```
这里通常提及的只有cpu使用的cache，个人理解，如果设备也需要用到cache的话，接口内部
应该也做相应的处理：
* dma_sync_{single/sg}_for_cpu() 需要先将设备的cache flush到ddr中，然后才将cpu的
cache标为无效，重新加载；
* 同样dma_sync_{single/sg}_for_device()需要现将cpu 的cache flush到ddr中，然后才
将设备的cache标为无效，重新加载


```
注意
dma_sync_sg_for_cpu() 和 dma_sync_sg_for_device() 的“nents”参数必须与传递给
dma_map_sg() 的参数相同。它不是 dma_map_sg() 返回的计数。

同步 CPU 和设备的单个连续或分散/聚集映射。对于sync_sg API，所有参数必须与传递
到单个映射API 的参数相同。通过sync_single API，您可以使用与传递到单个映射API
中的参数不同的dma_handle 和size 参数来执行部分同步。

以下位置做数据同步非常必要：
在从设备读取 DMA 写入的值之前（使用 DMA_FROM_DEVICE 方向）
写入将使用 DMA（使用 DMA_TO_DEVICE）方向写入设备的值后
如果内存是 DMA_BIDIRECTIONAL，则将内存交给设备之前和之后
```

最后一次 DMA 传输后，取消 DMA 映射： dma_unmap_{single,sg}()。

如果不接触dma_map_*() 调用直到 dma_unmap_*() 之间的数据，那么根本不必调用 dma_sync_*()

下面的伪代码显示了需要使用 dma_sync_*() 接口的情况：
```c
my_card_setup_receive_buffer(struct my_card *cp, char *buffer, int len)
{
        dma_addr_t mapping;

        mapping = dma_map_single(cp->dev, buffer, len, DMA_FROM_DEVICE);
        if (dma_mapping_error(cp->dev, mapping)) {
                /*
                 * reduce current DMA mapping usage,
                 * delay and try again later or
                 * reset driver.
                 */
                goto map_error_handling;
        }

        cp->rx_buf = buffer;
        cp->rx_len = len;
        cp->rx_dma = mapping;

        give_rx_buf_to_card(cp);
}

...

my_card_interrupt_handler(int irq, void *devid, struct pt_regs *regs)
{
        struct my_card *cp = devid;

        ...
        if (read_card_status(cp) == RX_BUF_TRANSFERRED) {
                struct my_card_header *hp;

                /* Examine the header to see if we wish
                 * to accept the data.  But synchronize
                 * the DMA transfer with the CPU first
                 * so that we see updated contents.
                 */
                dma_sync_single_for_cpu(&cp->dev, cp->rx_dma,
                                        cp->rx_len,
                                        DMA_FROM_DEVICE);

                /* Now it is safe to examine the buffer. */
                hp = (struct my_card_header *) cp->rx_buf;
                if (header_is_ok(hp)) {
                        dma_unmap_single(&cp->dev, cp->rx_dma, cp->rx_len,
                                         DMA_FROM_DEVICE);
                        pass_to_upper_layers(cp->rx_buf);
                        make_and_setup_new_rx_buf(cp);
                } else {
                        /* CPU should not write to
                         * DMA_FROM_DEVICE-mapped area,
                         * so dma_sync_single_for_device() is
                         * not needed here. It would be required
                         * for DMA_BIDIRECTIONAL mapping if
                         * the memory was modified.
                         */
                        give_rx_buf_to_card(cp);
                }
        }
}
```

### Non-coherent DMA allocations

这些 API 可以为指定设备申请 DMA 寻址的 页面，但需要对内核与设备的内存所有权进行
显式管理。

如果不了解处理器和 I/O 设备之间的缓存行一致性如何工作，则不应使用这些 API。
```c
struct page *
dma_alloc_pages(struct device *dev, size_t size, dma_addr_t *dma_handle,
                enum dma_data_direction dir, gfp_t gfp)
// 分配 size 字节的非一致性内存区域。它返回指向该区域的第一个结构页的指针，如果分配失败
// 则返回 NULL。它还返回一个dma_handle，可以作为该区域的 DMA 基地址提供给设备。
//
// dir 参数指定设备是否读取和/或写入数据，有关详细信息，请参阅 dma_map_single()。
//
// gfp 参数允许调用者指定分配的GFP_标志（请参阅 kmalloc()参考资料），但不应用于指定
// 内存区域的标志，例如 GFP_DMA 或 GFP_HIGHMEM。
//
// 在将内存提供给设备之前，需要调用 dma_sync_single_for_device()，并且在读取设备
// 写入的内存之前，需要调用 dma_sync_single_for_cpu()，就像双向数据传递的流式
// DMA 映射一样。
```
```c
void
dma_free_pages(struct device *dev, size_t size, struct page *page,
                dma_addr_t dma_handle, enum dma_data_direction dir)
// 释放先前使用 dma_alloc_pages() 分配的内存区域。dev、size、dma_handle 和 dir 必须与
// 传递到 dma_alloc_pages() 的值相同。page 必须是 dma_alloc_pages() 返回的指针。
```
```c
int
dma_mmap_pages(struct device *dev, struct vm_area_struct *vma,
               size_t size, struct page *page)

// 将从 dma_alloc_pages() 返回的分配映射到用户地址空间。dev 和 size 必须与传递给
// dma_alloc_pages() 的值相同。page 必须是 dma_alloc_pages() 返回的指针。
```
```c
void *
dma_alloc_noncoherent(struct device *dev, size_t size,
                dma_addr_t *dma_handle, enum dma_data_direction dir,
                gfp_t gfp)
// 该例程是 dma_alloc_pages 的便捷包装器，它返回已分配内存的内核虚拟地址而不是页面结构。
```
```c
void
dma_free_noncoherent(struct device *dev, size_t size, void *cpu_addr,
                dma_addr_t dma_handle, enum dma_data_direction dir)

// 释放先前使用 dma_alloc_noncoherent() 分配的内存区域。
// dev、size、dma_handle 和 dir 必须与传入 dma_alloc_noncoherent() 的值相同。
// cpu_addr 必须是 dma_alloc_noncoherent() 返回的虚拟地址。
```
```c
struct sg_table *
dma_alloc_noncontiguous(struct device *dev, size_t size,
                        enum dma_data_direction dir, gfp_t gfp,
                        unsigned long attrs);
// 此例程分配 size 字节的非一致性且可能不连续的内存。它返回一个指向 struct sg_table
// 的散列表指针，该结构描述了已分配和 DMA 映射的内存，如果分配失败，则返回 NULL。
//
// 返回的 sg_table 保证具有 1 个 DMA 映射段，如 sgt->nents 所示，但它可能具有多个
// CPU 端段，如 sgt->orig_nents 所示。
//
// dir 参数指定设备是否读取和/或写入数据，有关详细信息，请参阅 dma_map_single()。
//
// gfp 参数允许调用者指定分配的GFP_标志（请参阅 kmalloc()参考资料），但不应用于指定内存区域
// 的标志，例如 GFP_DMA 或 GFP_HIGHMEM。
//
// attrs 参数必须为 0 或 DMA_ATTR_ALLOC_SINGLE_PAGES。
//
// 在将内存提供给设备之前，需要调用 dma_sync_sgtable_for_device()，并且在读取设备写入的
// 内存之前，需要调用 dma_sync_sgtable_for_cpu()，就像双向数据传递的流式 DMA 映射一样。
```
```c
void
dma_free_noncontiguous(struct device *dev, size_t size,
                       struct sg_table *sgt,
                       enum dma_data_direction dir)
// 释放先前使用 dma_alloc_noncontigious() 分配的内存。
// dev、size 和 dir 必须与传递到 dma_alloc_noncontigious() 的值相同。
// sgt 必须是 dma_alloc_noncontigious() 返回的指针。
```
```c
void *
dma_vmap_noncontiguous(struct device *dev, size_t size,
        struct sg_table *sgt)
// 返回从 dma_alloc_noncontigious() 返回的分配的连续内核虚拟地址映射。
// dev 和 size 必须与传递给 dma_alloc_noncontigious() 的值相同。
// sgt 必须是 dma_alloc_noncontigious() 返回的指针。

// 使用此函数映射非连续分配后，必须使用flush_kernel_vmap_range() 和
// invalidate_kernel_vmap_range() API 来管理内核映射、设备和用户空间映射（如果有）
// 之间的一致性。
```
```c
void
dma_vunmap_noncontiguous(struct device *dev, void *vaddr)

// 取消映射由 dma_vmap_noncontigious() 返回的内核虚拟地址映射。
// dev 必须与传递到 dma_alloc_noncontigious() 的相同。
// vaddr 必须是 dma_vmap_noncontigious() 返回的指针。
```
```c
int
dma_mmap_noncontiguous(struct device *dev, struct vm_area_struct *vma,
                       size_t size, struct sg_table *sgt)
// 将从 dma_alloc_noncontigious() 返回的分配映射到用户地址空间。
// dev 和 size 必须与传递给 dma_alloc_noncontigious() 的值相同。
// sgt 必须是 dma_alloc_noncontigious() 返回的指针。
```
```c
int
dma_get_cache_alignment(void)
// 返回处理器缓存对齐方式。这是映射内存或进行部分刷新时必须遵守的绝对最小对齐和宽度。
```

```
注意：
此 API 可能返回一个大于实际缓存行的数字，但它将保证一个或多个缓存行完全适合此调用
返回的宽度。它也始终是 2 的幂，以便于对齐。
```

## 等待 DMA 完成

完整描述可查阅 Documentation/scheduler/completeion.txt

需要包含头文件： `<linux/completion.h>`

像其他内核功能的数据结构一样，可以静态和动态的创建`struct completion`结构体的实例
静态声明和初始化：`DECLARE_COMPLETION(my_comp);`
动态分配：`struct completion my_comp;` `init_completion(&my_comp);`

当驱动程序启动的工作必须等待完成时，他可以用以下形式之一唤醒正在等待的任何人（这里
指需要访问DMA缓冲区的代码）：
```c
void complete(struct completion *comp);
void complete_all(struct completion *comp);
```
以上 complete 只会唤醒一个等待进程，而complete_all会唤醒等待的所有进程。以这样的
实现，即使在wait_for_completion()之前调用complete()，完成也将正常工作。

## 错误处理
DMA 地址空间在某些架构上受到限制，分配失败可以通过以下方式确定：
* 检查 dma_alloc_coherent() 是否返回 NULL 或 dma_map_sg 返回 0
* 使用 dma_mapping_error() 检查 dma_map_single() 和 dma_map_page() 返回的 dma_addr_t
```c
dma_addr_t dma_handle;

dma_handle = dma_map_single(dev, addr, size, direction);
if (dma_mapping_error(dev, dma_handle)) {
        /*
         * reduce current DMA mapping usage,
         * delay and try again later or
         * reset driver.
         */
        goto map_error_handling;
}
```
* 当多页映射尝试过程中发生映射错误时，取消映射已映射的页。这些示例也适用于 dma_map_page()。

示例1：
```c
dma_addr_t dma_handle1;
dma_addr_t dma_handle2;

dma_handle1 = dma_map_single(dev, addr, size, direction);
if (dma_mapping_error(dev, dma_handle1)) {
        /*
         * reduce current DMA mapping usage,
         * delay and try again later or
         * reset driver.
         */
        goto map_error_handling1;
}
dma_handle2 = dma_map_single(dev, addr, size, direction);
if (dma_mapping_error(dev, dma_handle2)) {
        /*
         * reduce current DMA mapping usage,
         * delay and try again later or
         * reset driver.
         */
        goto map_error_handling2;
}

...

map_error_handling2:
        dma_unmap_single(dma_handle1);
map_error_handling1:
```
示例2：
```c
/*
 * if buffers are allocated in a loop, unmap all mapped buffers when
 * mapping error is detected in the middle
 */

dma_addr_t dma_addr;
dma_addr_t array[DMA_BUFFERS];
int save_index = 0;

for (i = 0; i < DMA_BUFFERS; i++) {

        ...

        dma_addr = dma_map_single(dev, addr, size, direction);
        if (dma_mapping_error(dev, dma_addr)) {
                /*
                 * reduce current DMA mapping usage,
                 * delay and try again later or
                 * reset driver.
                 */
                goto map_error_handling;
        }
        array[i].dma_addr = dma_addr;
        save_index++;
}

...

map_error_handling:

for (i = 0; i < save_index; i++) {

        ...

        dma_unmap_single(array[i].dma_addr);
}
```
如果传输hack (ndo_start_xmit) 上的 DMA 映射失败，网络驱动程序必须调用 dev_kfree_skb()
来释放套接字缓冲区并返回 NETDEV_TX_OK。这意味着在失败情况下套接字缓冲区将被丢弃。

如果队列命令hack中的 DMA 映射失败，SCSI 驱动程序必须返回 SCSI_MLQUEUE_HOST_BUSY。
这意味着 SCSI 子系统稍后会再次将命令传递给驱动程序。


## 使用 DMA-API 调试 DMA

如上所述的 DMA-API 有一些限制。例如，DMA 地址必须使用相应的函数释放相同的大小。
随着硬件 IOMMU 的出现，驱动程序不违反这些约束变得越来越重要。在最坏的情况下，这种
违规行为可能会导致数据损坏甚至文件系统损坏。

为了调试驱动程序并查找 DMA-API 使用中的错误，可以将检查代码编译到内核中，该内核
将告诉开发人员这些违规情况。如果您的架构支持，您可以在内核配置中选择“启用 DMA-API
使用调试”选项。启用此选项会对性能产生影响。不要在生产内核中启用它。

如果启动，生成的内核将包含一些代码，这些代码会记录为哪个设备分配了哪些 DMA 内存。
如果此代码检测到错误，它会在内核日志中打印一条警告消息，其中包含一些详细信息。
警告消息示例可能如下所示：
```
WARNING: at /data2/repos/linux-2.6-iommu/lib/dma-debug.c:448
        check_unmap+0x203/0x490()
Hardware name:
forcedeth 0000:00:08.0: DMA-API: device driver frees DMA memory with wrong
        function [device address=0x00000000640444be] [size=66 bytes] [mapped as
single] [unmapped as page]
Modules linked in: nfsd exportfs bridge stp llc r8169
Pid: 0, comm: swapper Tainted: G        W  2.6.28-dmatest-09289-g8bb99c0 #1
Call Trace:
<IRQ>  [<ffffffff80240b22>] warn_slowpath+0xf2/0x130
[<ffffffff80647b70>] _spin_unlock+0x10/0x30
[<ffffffff80537e75>] usb_hcd_link_urb_to_ep+0x75/0xc0
[<ffffffff80647c22>] _spin_unlock_irqrestore+0x12/0x40
[<ffffffff8055347f>] ohci_urb_enqueue+0x19f/0x7c0
[<ffffffff80252f96>] queue_work+0x56/0x60
[<ffffffff80237e10>] enqueue_task_fair+0x20/0x50
[<ffffffff80539279>] usb_hcd_submit_urb+0x379/0xbc0
[<ffffffff803b78c3>] cpumask_next_and+0x23/0x40
[<ffffffff80235177>] find_busiest_group+0x207/0x8a0
[<ffffffff8064784f>] _spin_lock_irqsave+0x1f/0x50
[<ffffffff803c7ea3>] check_unmap+0x203/0x490
[<ffffffff803c8259>] debug_dma_unmap_page+0x49/0x50
[<ffffffff80485f26>] nv_tx_done_optimized+0xc6/0x2c0
[<ffffffff80486c13>] nv_nic_irq_optimized+0x73/0x2b0
[<ffffffff8026df84>] handle_IRQ_event+0x34/0x70
[<ffffffff8026ffe9>] handle_edge_irq+0xc9/0x150
[<ffffffff8020e3ab>] do_IRQ+0xcb/0x1c0
[<ffffffff8020c093>] ret_from_intr+0x0/0xa
<EOI> <4>---[ end trace f6435a98e2a38c0e ]---
```
驱动程序开发人员可以找到驱动程序和设备，包括导致此警告的 DMA-API 调用的堆栈跟踪。

默认情况下，只有第一个错误才会产生警告消息。所有其他错误只会默默地计算。此限制的
存在是为了防止代码淹没您的内核日志。为了支持调试设备驱动程序，可以通过 debugfs
禁用此功能。有关详细信息，请参阅下面的 debugfs 接口文档。

DMA-API 调试代码的 debugfs 目录称为 dma-api/。目前可以在此目录中找到以下文件：


|||
|----|----|
| dma-api/all_errors | 该文件包含一个数值。如果该值不等于 0，则调试代码将为在内核日志中发现的每个错误打印一条警告。请小心使用此选项，因为它很容易淹没您的日志。 |
| DMA-API/禁用 | 如果禁用调试代码，则此只读文件包含字符“Y”。当内存不足或在启动时被禁用时，可能会发生这种情况 |
| DMA-API/转储 | 该只读文件包含当前的 DMA 映射。 |
| dma-api/错误计数 | 该文件是只读的，显示发现的错误总数。 |
| dma-api/num_errors | 该文件中的数字显示在停止之前将有多少警告打印到内核日志中。该数字在系统启动时初始化为 1，并通过写入此文件来设置 |
| dma-api/min_free_entries | 可以读取此只读文件以获得分配器所见过的最小数量的空闲 dma_debug_entries。如果该值降至零，代码将尝试增加 nr_total_entries 进行补偿。 |
| dma-api/num_free_entries | 分配器中当前空闲 dma_debug_entries 的数量。 |
| dma-api/nr_total_entries | 分配器中的 dma_debug_entries 总数，包括空闲的和已使用的。 |
| dma-api/driver_filter | 您可以将驱动程序的名称写入此文件，以将调试输出限制为来自该特定驱动程序的请求。将空字符串写入该文件以禁用过滤器并再次查看所有错误。 |

如果您将此代码编译到内核中，它将默认启用。如果您想在没有簿记的情况下启动，您可以
提供“dma_debug=off”作为启动参数。这将禁用 DMA-API 调试。请注意，您无法在运行时
再次启用它。您必须重新启动才能执行此操作。

如果您只想查看特殊设备驱动程序的调试消息，可以指定 dma_debug_driver=<drivername>
参数。这将在启动时启用驱动程序过滤器。之后调试代码只会打印该驱动程序的错误。稍后
可以使用 debugfs 禁用或更改此过滤器。

当代码在运行时禁用自身时，这很可能是因为它耗尽了 dma_debug_entries 并且无法按需
分配更多。65536 个条目在启动时预先分配 - 如果这对于您使用“dma_debug_entries=
<your_desired_number>”启动来覆盖默认值来说太低。请注意，代码会批量分配条目，因此
预分配条目的确切数量可能大于实际请求的数量。每次动态分配与最初预分配一样多的条目
时，代码都会打印到内核日志。这表明较大的预分配大小可能是合适的，或者如果连续发生
驱动程序可能会泄漏映射。
```c
void
debug_dma_mapping_error(struct device *dev, dma_addr_t dma_addr);
```
dma-debug 接口 debug_dma_mapping_error() 用于调试无法检查 dma_map_single() 和
dma_map_page() 接口返回的地址上的 DMA 映射错误的驱动程序。该接口清除由
debug_dma_map_page() 设置的标志，以指示 dma_mapping_error() 已被驱动程序调用。
当驱动程序取消映射时，debug_dma_unmap() 检查该标志，如果该标志仍然设置，则打印
警告消息，其中包括导致取消映射的调用跟踪。可以从 dma_mapping_error() 例程调用该
接口以启用 DMA 映射错误检查调试。


## 优化取消映射状态空间消耗

在许多平台上，dma_unmap_{single,page}() 只是一个 nop。因此，跟踪映射地址和长度是
浪费空间。不是用 ifdef 等填充驱动程序来解决这个问题（这会破坏可移植 API 的全部
目的），而是提供以下功能。

以下不会一一描述宏，而是转换一些示例代码。

1. 在状态保存结构中使用 DEFINE_DMA_UNMAP_{ADDR,LEN}：
```c
// 之前的例子
struct ring_state {
        struct sk_buff *skb;
        dma_addr_t mapping;
        __u32 len;
};
// 之后：
struct ring_state {
        struct sk_buff *skb;
        DEFINE_DMA_UNMAP_ADDR(mapping);
        DEFINE_DMA_UNMAP_LEN(len);
};
```
2. 使用 dma_unmap_{addr,len}_set() 设置这些值：
```c
// 之前的例子
ringp->mapping = FOO;
ringp->len = BAR;
// 之后：
dma_unmap_addr_set(ringp, mapping, FOO);
dma_unmap_len_set(ringp, len, BAR);
```
3. 使用 dma_unmap_{addr,len}() 访问这些值：
```c
// 之前的例子
dma_unmap_single(dev, ringp->mapping, ringp->len,
                 DMA_FROM_DEVICE);
// 之后：
dma_unmap_single(dev,
                 dma_unmap_addr(ringp, mapping),
                 dma_unmap_len(ringp, len),
                 DMA_FROM_DEVICE);
```
这是不言自明的。我们单独对待 ADDR 和 LEN，因为实现可能只需要地址即可执行取消映射
操作。

